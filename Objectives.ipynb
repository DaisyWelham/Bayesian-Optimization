{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1838e5e1-b6bc-4968-9e80-4da5a5587ff9",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bfee14-749c-44fc-bd52-b62357e5550b",
   "metadata": {},
   "source": [
    "In this notebook I list various objective functions for optimization problems, and I group similar functions together. At the bottom there's also the random search class, so you can optimize any objective listed here by setting it to \"obj\" and modifying random search's ranges. By default I set the semi-empirical mass formula as \"obj\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237a4b92-7b3e-436e-a6b0-874a75b31033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d36ed5-dca7-4782-a743-076d38f4aa6c",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237cb494-d491-4c57-8eb9-3781c76287b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSearch:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ranges\n",
    "    ):\n",
    "        self.ranges = ranges\n",
    "        \n",
    "    def generateRandomHypothesis(self):\n",
    "        output = []\n",
    "        for x in self.ranges:\n",
    "            output.append(r.uniform(x[0], x[1]))\n",
    "        return(output)\n",
    "    \n",
    "    def optimize(self,\n",
    "                objectiveFunction,\n",
    "                numIterations = 25000):\n",
    "        bestX = None\n",
    "        bestY = -float(\"inf\")\n",
    "        for i in range(numIterations):\n",
    "            newX = self.generateRandomHypothesis()\n",
    "            newY = objectiveFunction(newX)\n",
    "            if newY > bestY:\n",
    "                bestX = newX\n",
    "                bestY = newY\n",
    "        return(bestX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c724d8-8719-40c5-a0ae-ef6098971083",
   "metadata": {},
   "source": [
    "## Physics Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54771aee-3560-499c-8164-130e95ca8416",
   "metadata": {},
   "source": [
    "### Drag Minimization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba464db-e6dc-42e9-b1c6-0753d7e75fac",
   "metadata": {},
   "source": [
    "The drag per second a vehicle travelling on a road experiences is approximately R(v) = Av^2 + Bv + C where A is a factor relating aerodynamics, B to rolling and drivetrain losses, and C is a constant load. If t is the time taken to arrive at a destination D, minimizing t x R will minimize the losses due to drag for the journey. Since v = D/t and D is constant this is equivalent to minimizing R/v, i.e. Av + B + C/v. \n",
    "\n",
    "Suppose we have a car with A = 0.6, B = 5, C = 80, we have a well-defined optimization problem. It's fun to play around with A/B/C and see how different physical parameters affect the optimum speed. most cars travel ~30mph most of the time, so we expect an answer near 13m/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe7d5f4-9f4b-47b4-b0b6-ded65e25af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dragMinimization(\n",
    "    hypothesis,\n",
    "    aerodynamicsConstant = 0.6,\n",
    "    rollingConstant = 5,\n",
    "    loadConstant = 80\n",
    "):\n",
    "    v = hypothesis[0]\n",
    "    aTerm = aerodynamicsConstant * v \n",
    "    bTerm = rollingConstant\n",
    "    cTerm = loadConstant / v\n",
    "    output = - (aTerm + bTerm + cTerm)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06cde57b-7698-4315-b76f-451a8720f62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.547810193386631]\n"
     ]
    }
   ],
   "source": [
    "rs = RandomSearch([[0, 50]])\n",
    "print(rs.optimize(dragMinimization))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c72810-a612-435a-bf57-46879063b48a",
   "metadata": {},
   "source": [
    "### Semi-Empirical Masss Formula (SEMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a49fcb-6181-4db3-a76a-b49cce0f6d2f",
   "metadata": {},
   "source": [
    "Below is the semi-empirical mass formula. It's a formula from physics which gives us the binding energy of a nucleus given its proton number, Z, and neutron number, N. Since physics is effectively trying to maximise the binding energy per nucleon, we have a fun optimization problem if we divide the energy predicted by the SEMF by Z + N. You can play around with physics and see which isotopes would be stable if you changed, say, the Coulomb term! \n",
    "\n",
    "SEMF is also useful since it has a known best result of Nickel-62: Z = 28, N = 34. The closer the output is to this, the better our algorithm is doing. Another very stable isotope is Iron-56: Z = 26, N = 30, so if we get a result close to this the algorithm has done well, too.\n",
    "\n",
    "More about the SEMF here: https://en.wikipedia.org/wiki/Semi-empirical_mass_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cda7006-1a8a-4f09-b05b-fc87e6651587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26.23921174602158, 32.26284512105376]\n"
     ]
    }
   ],
   "source": [
    "def SEMF(\n",
    "    hypothesis, \n",
    "    volumeConstant = 15.8,\n",
    "    surfaceConstant = 17.8,\n",
    "    coulombConstant = 0.711,\n",
    "    asymmetryConstant = 23.7,\n",
    "    pairingConstant = 11.18\n",
    "):\n",
    "    \n",
    "    #Physical info from hypothesis\n",
    "    Z = int(hypothesis[0]) #Proton number\n",
    "    N = int(hypothesis[1]) #Neutron number\n",
    "    A = Z + N              #Nucleon number\n",
    "    \n",
    "    #Calculate each term\n",
    "    volumeTerm = volumeConstant * A\n",
    "    surfaceTerm = -surfaceConstant * A ** (2/3)\n",
    "    coulombTerm = -coulombConstant * Z * (Z - 1) * A ** (-1/3)\n",
    "    asymmetryTerm = -asymmetryConstant * ((N - Z) ** 2) / A\n",
    "    \n",
    "    #Pairing term\n",
    "    if A % 2 == 1:\n",
    "        pairingTerm = 0\n",
    "    elif Z % 2 == 0 and N % 2 == 0:\n",
    "        pairingTerm = pairingConstant * A ** (-1/2)\n",
    "    elif Z % 2 == 1 and N % 2 == 1:\n",
    "        pairingTerm = -pairingConstant * A ** (-1/2)\n",
    "    else:\n",
    "        pairingTerm = 0\n",
    "    output = (volumeTerm + surfaceTerm + coulombTerm + asymmetryTerm + pairingTerm) / A\n",
    "    return(output)\n",
    "\n",
    "rs = RandomSearch([[1, 120], [1, 180]])\n",
    "print(rs.optimize(SEMF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3484e1ea-c58d-4f18-8400-d0f8f4cb5c39",
   "metadata": {},
   "source": [
    "## Game Theory Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90aabee-ed61-4581-9de3-e9fcfa2d6df8",
   "metadata": {},
   "source": [
    "### El Farol Bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44aff60-9dac-407e-a24c-f367d473a484",
   "metadata": {},
   "source": [
    "With El Farol Bar, we assume there are several bars in town, say 5. Each bar has a base \"niceness\" value N, and we're antisocial nerds so we prefer bars with fewer people in. Thus the utility we would get for attending each bar is N^-kx where x is the number of other people in the bar and k some decay constant. \n",
    "\n",
    "Classic El Farol asks us to come up with a strategy for which bar to go to given other people are more likely to go to nicer bars, but I prefer to ask what the optimal distribution of people across bars is to maximise their culmulative utility. Thus we maximise the sum of xN^-kx for each N, x. (For convenience, k is constant across all bars).\n",
    "\n",
    "We enforce that the number of people in each bar must be an integer, and the total number of people in all bars is free to vary (some people stay home and write code for GitHub instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "088934fb-945b-4f53-bc99-a4d5304bbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "barUtilities = [10, 20, 40, 80, 160]\n",
    "decayConstant = 0.5\n",
    "\n",
    "def singleBarUtility(x, barNumber):\n",
    "    output = x * barUtilities[barNumber] ** (-decayConstant * (x - 1))\n",
    "    return(output)\n",
    "\n",
    "def elFarol(hypothesis):\n",
    "    peopleAssignments = [int(x) for x in hypothesis]\n",
    "    output = 0\n",
    "    for i in range(len(barUtilities)):\n",
    "        output += singleBarUtility(peopleAssignments[i], i)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8499c08e-1d36-40e9-9fb0-de88f64d1e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 45, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "ranges = []\n",
    "for i in range(len(barUtilities)):\n",
    "    ranges.append([0, 50])\n",
    "\n",
    "rs = RandomSearch(ranges)\n",
    "distribution = rs.optimize(elFarol)\n",
    "print([int(x) for x in distribution])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464258dd-381c-486c-b1ce-27ee47bf71c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
